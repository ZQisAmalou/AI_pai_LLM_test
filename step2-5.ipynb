{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0cc7e20-14f2-4d2e-9f67-f46b6edcdb75",
   "metadata": {},
   "source": [
    "## Êï∞ÊçÆÈõÜ‰∏ãËΩΩ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "755df3be-a010-458c-9b43-9f9a268287bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoModelForCausalLM,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "\n",
    "# IMDBÊï∞ÊçÆÈõÜ\n",
    "ds = load_dataset(\"stanfordnlp/imdb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0802aa63-13e6-401f-9343-684e9e249cf2",
   "metadata": {},
   "source": [
    "## BERTÊµãËØï"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b95edec-ce8d-44bb-926b-9e86effa8643",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/root/miniconda3/lib/python3.12/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3126' max='3126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3126/3126 12:03, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.246600</td>\n",
       "      <td>0.210196</td>\n",
       "      <td>0.919360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.114800</td>\n",
       "      <td>0.246060</td>\n",
       "      <td>0.940560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1563' max='1563' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1563/1563 01:28]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT accuracy: 0.9194\n"
     ]
    }
   ],
   "source": [
    "# ËØÑ‰ª∑ÊåáÊ†á\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    return {\"accuracy\": accuracy_score(p.label_ids, preds)}\n",
    "\n",
    "# BERTÊ®°ÂûãÂíåtokenizer\n",
    "model_name_bert = \"google-bert/bert-base-uncased\"\n",
    "tokenizer_bert = AutoTokenizer.from_pretrained(model_name_bert)\n",
    "model_bert = AutoModelForSequenceClassification.from_pretrained(model_name_bert, num_labels=2)\n",
    "\n",
    "\n",
    "# Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜ\n",
    "def preprocess_function_bert(examples):\n",
    "    return tokenizer_bert(examples['text'], truncation=True)\n",
    "\n",
    "\n",
    "encoded_ds_bert = ds.map(preprocess_function_bert, batched=True)\n",
    "\n",
    "# ËÆ≠ÁªÉÂèÇÊï∞\n",
    "training_args_bert = TrainingArguments(\n",
    "    output_dir=\"./results_bert\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    logging_dir=\"./logs_bert\",\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "# ËÆ≠ÁªÉ\n",
    "trainer_bert = Trainer(\n",
    "    model=model_bert,\n",
    "    args=training_args_bert,\n",
    "    train_dataset=encoded_ds_bert[\"train\"],\n",
    "    eval_dataset=encoded_ds_bert[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer_bert,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer_bert)\n",
    ")\n",
    "\n",
    "trainer_bert.train()\n",
    "results_bert = trainer_bert.evaluate()\n",
    "print(f\"BERT accuracy: {results_bert['eval_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117a9f5b-d1ab-45b3-90c4-8698117998fb",
   "metadata": {},
   "source": [
    "## GPT-2 ÊµãËØï"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0433ade1-f021-4b3f-8469-375e033d80cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/root/miniconda3/lib/python3.12/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='814' max='3126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 814/3126 05:04 < 14:25, 2.67 it/s, Epoch 0.52/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 40\u001b[0m\n\u001b[1;32m     29\u001b[0m trainer_gpt2 \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     30\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel_gpt2,\n\u001b[1;32m     31\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args_gpt2,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mDataCollatorWithPadding(tokenizer_gpt2)\n\u001b[1;32m     37\u001b[0m )\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# ËÆ≠ÁªÉÂπ∂ËØÑ‰º∞Ê®°Âûã\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m \u001b[43mtrainer_gpt2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m results_gpt2 \u001b[38;5;241m=\u001b[39m trainer_gpt2\u001b[38;5;241m.\u001b[39mevaluate()\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPT-2 accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults_gpt2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/transformers/trainer.py:1938\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1936\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1937\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1938\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1939\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/transformers/trainer.py:2284\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2278\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m   2279\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   2281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2282\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2283\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m-> 2284\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2285\u001b[0m ):\n\u001b[1;32m   2286\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2287\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2288\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Âä†ËΩΩGPT-2Ê®°ÂûãÂíåtokenizer\n",
    "model_name_gpt2 = \"openai-community/gpt2\"\n",
    "tokenizer_gpt2 = AutoTokenizer.from_pretrained(model_name_gpt2)\n",
    "model_gpt2 = AutoModelForSequenceClassification.from_pretrained(model_name_gpt2, num_labels=2)\n",
    "\n",
    "# ÊåáÂÆöÂ°´ÂÖÖtoken\n",
    "tokenizer_gpt2.pad_token = tokenizer_gpt2.eos_token\n",
    "model_gpt2.config.pad_token_id = tokenizer_gpt2.pad_token_id  # ÊâãÂä®ËÆæÁΩÆpad_token_id\n",
    "\n",
    "# Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜ\n",
    "def preprocess_function_gpt2(examples):\n",
    "    return tokenizer_gpt2(examples['text'], truncation=True)\n",
    "\n",
    "encoded_ds_gpt2 = ds.map(preprocess_function_gpt2, batched=True)\n",
    "\n",
    "# ËÆ≠ÁªÉÂèÇÊï∞\n",
    "training_args_gpt2 = TrainingArguments(\n",
    "    output_dir=\"./results_gpt2\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    logging_dir=\"./logs_gpt2\",\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "trainer_gpt2 = Trainer(\n",
    "    model=model_gpt2,\n",
    "    args=training_args_gpt2,\n",
    "    train_dataset=encoded_ds_gpt2[\"train\"],\n",
    "    eval_dataset=encoded_ds_gpt2[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer_gpt2,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer_gpt2)\n",
    ")\n",
    "\n",
    "# ËÆ≠ÁªÉÂπ∂ËØÑ‰º∞Ê®°Âûã\n",
    "trainer_gpt2.train()\n",
    "results_gpt2 = trainer_gpt2.evaluate()\n",
    "print(f\"GPT-2 accuracy: {results_gpt2['eval_accuracy']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8028751e-1c98-407f-94b7-69bbad0c0d22",
   "metadata": {},
   "source": [
    "## gemma-2-2b-it-bnb-4bitÊµãËØï"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c68b1e36-616d-43ae-93a8-001b6ff70cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-shot accuracy: 1.0000\n",
      "2-shot accuracy: 1.0000\n",
      "4-shot accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "\n",
    "ds = load_dataset(\"stanfordnlp/imdb\")\n",
    "test_ds = ds['test'].select(range(200))\n",
    "\n",
    "model_id = \"unsloth/gemma-2-2b-it-bnb-4bit\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, device_map='auto')\n",
    "\n",
    "# ËÆ°ÁÆóÂáÜÁ°ÆÁéá\n",
    "def compute_accuracy(preds, labels):\n",
    "    correct = 0\n",
    "    for pred, label in zip(preds, labels):\n",
    "        if (\"positive\" in pred.lower() and label == 1) or (\"negative\" in pred.lower() and label == 0):\n",
    "            correct += 1\n",
    "    return correct / len(labels)\n",
    "\n",
    "# Zero-shot ÊÉÖÂÜµ‰∏ãÁöÑ prompt\n",
    "def zero_shot_prompt(text):\n",
    "    return f\"Classify the following movie review as positive or negative:\\n\\n{text}\\n\\nAnswer:\"\n",
    "\n",
    "# 2-shot Âíå 4-shot ÁöÑprompt\n",
    "def fixed_n_shot_prompt(text, shots):\n",
    "    if shots == 2:\n",
    "        return (f\"Classify the sentiment of the following reviews. Each review is labeled as either 'positive' or 'negative':\\n\"\n",
    "                f\"1. I love this movie! It was fantastic.\\nLabel: positive\\n\"\n",
    "                f\"2. I didn't like this movie at all. It was boring.\\nLabel: negative\\n\\n\"\n",
    "                f\"Now classify the sentiment of this review:\\n{text}\\nSentiment:\")\n",
    "    elif shots == 4:\n",
    "        return (f\"Classify the sentiment of the following reviews. Each review is labeled as either 'positive' or 'negative':\\n\"\n",
    "                f\"1. I love this movie! It was fantastic.\\nLabel: positive\\n\"\n",
    "                f\"2. I didn't like this movie at all. It was boring.\\nLabel: negative\\n\"\n",
    "                f\"3. The plot was intriguing and the acting was superb.\\nLabel: positive\\n\"\n",
    "                f\"4. The movie was a waste of time. Terrible.\\nLabel: negative\\n\\n\"\n",
    "                f\"Now classify the sentiment of this review:\\n{text}\\nSentiment:\")\n",
    "\n",
    "# ÁîüÊàêÊ®°ÂûãÈ¢ÑÊµã\n",
    "def generate_predictions(model, tokenizer, dataset, shot_type=\"zero\", shots=None):\n",
    "    preds = []\n",
    "    for example in dataset:\n",
    "        text = example['text']\n",
    "        if shot_type == \"zero\":\n",
    "            prompt = zero_shot_prompt(text)\n",
    "        elif shot_type == \"n-shot\":\n",
    "            prompt = fixed_n_shot_prompt(text, shots)\n",
    "        \n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(**inputs, max_new_tokens=50)\n",
    "        preds.append(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "    return preds\n",
    "\n",
    "# Zero-shot ÊµãËØï\n",
    "zero_shot_preds = generate_predictions(model, tokenizer, test_ds, shot_type=\"zero\")\n",
    "zero_shot_accuracy = compute_accuracy(zero_shot_preds, [x['label'] for x in test_ds])\n",
    "print(f\"Zero-shot accuracy: {zero_shot_accuracy:.4f}\")\n",
    "\n",
    "# 2-shot ÊµãËØï\n",
    "two_shot_preds = generate_predictions(model, tokenizer, test_ds, shot_type=\"n-shot\", shots=2)\n",
    "two_shot_accuracy = compute_accuracy(two_shot_preds, [x['label'] for x in test_ds])\n",
    "print(f\"2-shot accuracy: {two_shot_accuracy:.4f}\")\n",
    "\n",
    "# 4-shot ÊµãËØï\n",
    "four_shot_preds = generate_predictions(model, tokenizer, test_ds, shot_type=\"n-shot\", shots=4)\n",
    "four_shot_accuracy = compute_accuracy(four_shot_preds, [x['label'] for x in test_ds])\n",
    "print(f\"4-shot accuracy: {four_shot_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1f3d27-6ab4-460b-b950-4e09abf476bb",
   "metadata": {},
   "source": [
    "## glm4-flashÊµãËØï"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "071a19ea-a5e2-4e54-a0dc-e5d23a35a9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-shot accuracy: 0.9600\n",
      "2-shot accuracy: 0.9650\n",
      "4-shot accuracy: 0.9650\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "from zhipuai import ZhipuAI\n",
    "\n",
    "# Âä†ËΩΩÊï∞ÊçÆÈõÜ\n",
    "dataset = load_dataset(\"stanfordnlp/imdb\")\n",
    "test_data = dataset['test'].select(range(200))\n",
    "\n",
    "client = ZhipuAI(api_key=\"c6c970d4cd4f13745d08adf923aefb7d.P7EC5rOHL54sJwaB\")\n",
    "\n",
    "# ÁîüÊàê zero-shot prompt\n",
    "def zero_shot_prompt(text):\n",
    "    return f\"Classify the sentiment of the following movie review as positive or negative:\\n\\n{text}\\n\\nAnswer:\"\n",
    "\n",
    "# ÁîüÊàê n-shot prompt\n",
    "def fixed_n_shot_prompt(text, shots):\n",
    "    if shots == 2:\n",
    "        return (f\"Classify the sentiment of the following reviews. Each review is labeled as either 'positive' or 'negative':\\n\"\n",
    "                f\"1. I love this movie! It was fantastic.\\nLabel: positive\\n\"\n",
    "                f\"2. I didn't like this movie at all. It was boring.\\nLabel: negative\\n\\n\"\n",
    "                f\"Now classify the sentiment of this review:\\n{text}\\nSentiment:\")\n",
    "    elif shots == 4:\n",
    "        return (f\"Classify the sentiment of the following reviews. Each review is labeled as either 'positive' or 'negative':\\n\"\n",
    "                f\"1. I love this movie! It was fantastic.\\nLabel: positive\\n\"\n",
    "                f\"2. I didn't like this movie at all. It was boring.\\nLabel: negative\\n\"\n",
    "                f\"3. The plot was intriguing and the acting was superb.\\nLabel: positive\\n\"\n",
    "                f\"4. The movie was a waste of time. Terrible.\\nLabel: negative\\n\\n\"\n",
    "                f\"Now classify the sentiment of this review:\\n{text}\\nSentiment:\")\n",
    "\n",
    "# Ëé∑ÂèñÊ®°ÂûãÈ¢ÑÊµã\n",
    "def get_prediction(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"glm-4-flash\", \n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    )\n",
    "    \n",
    "    choices = response.choices\n",
    "    if choices and choices[0].message:\n",
    "        return choices[0].message.content.strip()\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected response format: 'message' not found in response.\")\n",
    "\n",
    "# ËÆ°ÁÆóÂáÜÁ°ÆÁéá\n",
    "def compute_accuracy(preds, labels):\n",
    "    correct = 0\n",
    "    for pred, label in zip(preds, labels):\n",
    "        if (\"positive\" in pred.lower() and label == 1) or (\"negative\" in pred.lower() and label == 0):\n",
    "            correct += 1\n",
    "    return correct / len(labels)\n",
    "\n",
    "# ÁîüÊàêÊ®°ÂûãÈ¢ÑÊµã\n",
    "def generate_predictions(test_data, shot_type=\"zero\", shots=None):\n",
    "    preds = []\n",
    "    for example in test_data:\n",
    "        review_text = example['text']\n",
    "        if shot_type == \"zero\":\n",
    "            prompt = zero_shot_prompt(review_text)\n",
    "        elif shot_type == \"n-shot\":\n",
    "            prompt = fixed_n_shot_prompt(review_text, shots)\n",
    "        \n",
    "        pred = get_prediction(prompt)\n",
    "        preds.append(pred)\n",
    "    return preds\n",
    "\n",
    "# Zero-shot ÊµãËØï\n",
    "zero_shot_preds = generate_predictions(test_data, shot_type=\"zero\")\n",
    "zero_shot_accuracy = compute_accuracy(zero_shot_preds, [x['label'] for x in test_data])\n",
    "print(f\"Zero-shot accuracy: {zero_shot_accuracy:.4f}\")\n",
    "\n",
    "# 2-shot ÊµãËØï\n",
    "two_shot_preds = generate_predictions(test_data, shot_type=\"n-shot\", shots=2)\n",
    "two_shot_accuracy = compute_accuracy(two_shot_preds, [x['label'] for x in test_data])\n",
    "print(f\"2-shot accuracy: {two_shot_accuracy:.4f}\")\n",
    "\n",
    "# 4-shot ÊµãËØï\n",
    "four_shot_preds = generate_predictions(test_data, shot_type=\"n-shot\", shots=4)\n",
    "four_shot_accuracy = compute_accuracy(four_shot_preds, [x['label'] for x in test_data])\n",
    "print(f\"4-shot accuracy: {four_shot_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc07f25-5600-4eec-8e5b-0f835b6159b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
